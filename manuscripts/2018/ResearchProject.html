<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Rosin C. NGUEVEU :: Research project - Transparence et responsabilité des algorithmes de personnalisation</title>
    <meta name="description" content="Urls:Pdf: ">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://0.0.0.0:4000/manuscripts/2018/ResearchProject">
    <link rel="alternate" type="application/rss+xml" title="Rosin C. NGUEVEU" href="http://0.0.0.0:4000/feed.xml" />

    <link href='https://fonts.googleapis.com/css?family=EB+Garamond' rel='stylesheet' type='text/css'>
</head>


  <body>
  <div class="page">
    <header class="site-header">
    <a class="site-title" href="/">Rosin C. NGUEVEU</a>
    <nav class="site-nav">
        <a href="#" class="menu-icon menu.open">
            <svg viewBox="0 0 18 15">
                <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
                <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
                <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
        </a>
        <div class="trigger"><h1>Main Navigation</h1>
            <ul class="menu">
    
    
     <li><a href="/awards-publications/" class="page-link">Awards & Publications</a>
    
    </li>
    
    
     <li><a href="/teaching/" class="page-link">Teaching</a>
    
    </li>
    
    
     <li><a href="/cv/" class="page-link">CV</a>
    
    </li>
    
</ul>

        </div>
    </nav>
</header>


    <div class="post">
    <header class="post-header">
        <h1>Research project - Transparence et responsabilité des algorithmes de personnalisation</h1>
    </header>

    <h5 id="urls">Urls:</h5>
<p>Pdf: <a href="/docs/Projet_these_Rosin_C._NGUEVEU_no_FW.pdf"><img src="/images/icons/pdf_24.png" alt="download pdf" /></a></p>

<h5 id="abstract">Abstract</h5>

<blockquote>
  <p>Les avancées récentes dans le domaine de l’apprentissage automatique, ainsi que la disponibilité de grande masse de données ont transformé le paysage actuel, à tel point que les algorithmes d’apprentissage et de personnalisation sont maintenant présents dans quasiment toutes les sphères de notre société. Par exemple, les candidatures sur des postes ouverts en entreprise sont maintenant préfiltrées automatiquement, les outils de prédictions de taux de récidivisme de détenus (COMPAS) sont utilisés de manière courante dans certains comtés aux États-Unis, etc. En plus des atteintes liées au respect de la vie privée qui ne sont plus à démontrer, le développement de ces algorithmes soulève aussi des enjeux éthiques importants. 
En premier lieu, les données sur lesquelles ces algorithmes sont entraînés peuvent contenir des biais qui seraient reflétés à plus large échelle dans le processus de décision ce qui peut soulever des questions en termes d’équité et discrimination. La littérature fait état de plusieurs approches développées récemment afin de prévenir la discrimination dans l’utilisation des algorithmes qui se différencient en fonction de plusieurs critères en fonction de la définition de discrimination choisie, du point de vue adopté lors du processus d’apprentissage et de l’espace de caractérisation des données. Pour répondre à cette problématique, nous avons développé l’approche « GANSan », qui, tout en préservant la compréhensibilité des données produites en sortie et leur utilité, les assainies de sorte que l’attribut pouvant amener à discrimination ainsi que les corrélations existantes avec les autres attributs du profil sont éliminées. Le second enjeu éthique porte sur la transparence sur les décisions de l’algorithme. En effet, les nouvelles régulations telles que le règlement général européen sur la protection des données offrent aux individus la possibilité de questionner les décisions des algorithmes qui ont un impact important sur leur vie. Ainsi, pouvoir interpréter une décision par exemple en divulguant le « chemin de décision » d’un algorithme devient une nécessité pour les fournisseurs de services. La transparence permet ainsi non seulement de vérifier que des caractéristiques discriminantes sont exclues du processus de décision, mais aussi de renforcer la confiance dans l’algorithme et ses décisions (par exemple dans le contexte médical l’explication sur la raison d’une prédiction faite par l’algorithme est hautement importante).
Cette thèse se propose de s’attaquer aux deux enjeux sus-cités que sont la non-discrimination et la transparence dans le contexte des algorithmes d’apprentissage. Dans un premier temps, nous nous proposons d’analyser et de concevoir des méthodes permettant de préserver la qualité des données tout en retirant les biais non désirés qui peuvent conduire à discrimination. Nous nous focaliserons tout d’abord sur des approches de quantification de la discrimination tout en étudiant comment ces méthodes peuvent s’articuler avec les définitions de discrimination provenant du droit, de la sociologie et de l’éthique. Ensuite, nous analyserons les méthodes existantes et les adapterons en fonction des définitions préalablement établies. Nous évaluerons pour finir la stabilité de ces approches dans différentes situations. Dans le second axe de recherche qui porte sur la transparence, nous commencerons par étudier et comparer les méthodes garantissant l’interprétabilité. Enfin nous souhaitons nous servir de cette analyse pour développer de nouvelles méthodes pour découvrir et à quantifier la discrimination, notamment en caractérisant l’influence des entrées utilisées par les algorithmes pour prendre leurs décisions.</p>
</blockquote>

<h5 id="bibtex">Bibtex</h5>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml">@techreport{researchReport2018Ngueveu,
  author =        {Ngueveu, Rosin C.}, 
  title =         {Transparence et Responsabilité des Algorithmes de Personnalisation},
  institution =   {Departement d'informatique, Universit{\'e} du Qu{\'e}bec {\`a} Montr{\'e}al},
  keywords=       {Algorithms, Transparency, Fairness, GANSan, Accountability, Interpretability, INF9812},
  month =         {October},
  year  =         {2018},
  author1_email = {ngueveu.rosin_claude@courrier.uqam.ca},
  pages =         {53},
}</code></pre></figure>


</div>


    <footer class="site-footer">
    © 2018 Rosin C. NGUEVEU | Last updated: 11-18<br />
</footer>


    

    </div>
  </body>

</html>
